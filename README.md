# EixoAI - Chat Inteligente com PDFs

**Uma aplicaÃ§Ã£o RAG (Retrieval-Augmented Generation) completa com busca semÃ¢ntica, LLM e interface web.**

---

## ğŸ“š Sobre o Projeto

**EixoAI** Ã© um sistema inteligente que combina:
- ğŸ¤– **LLM (Large Language Models)** via Groq API
- ğŸ” **RAG (Retrieval-Augmented Generation)** com embeddings semÃ¢nticos
- ğŸ’¾ **ChromaDB** para persistÃªncia de vetores
- ğŸ›ï¸ **Interface Web** com Gradio
- ğŸ“„ **Processamento de PDFs** automÃ¡tico

O objetivo Ã© criar um **chatbot contextualizado** que entende documentos e responde perguntas com precisÃ£o usando busca semÃ¢ntica.

### âœ¨ CaracterÃ­sticas Principais

| Recurso | DescriÃ§Ã£o |
|---------|-----------|
| ğŸ“¤ **Upload de PDFs** | Carregue PDFs e o sistema processa automaticamente |
| ğŸ§  **Embeddings SemÃ¢nticos** | Gera embeddings consistentes com `sentence-transformers` |
| ğŸ” **Busca Inteligente** | Encontra o contexto mais relevante para cada pergunta |
| ğŸ’¬ **Chat com IA** | Conversa natural com a LLM usando contexto do PDF |
| ğŸ’¾ **PersistÃªncia** | Armazena embeddings em ChromaDB para reutilizaÃ§Ã£o |
| âš¡ **RÃ¡pido e Leve** | Usa modelo all-MiniLM-L6-v2 (eficiente) |
| ğŸ”§ **Tratamento de Erros** | Mostra erros como mensagens no chat |

---

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     EixoAI - Fluxo Completo                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  1. UPLOAD PDF                                              â”‚
â”‚     â†“                                                        â”‚
â”‚  2. EXTRAÃ‡ÃƒO (ingester.py)                                  â”‚
â”‚     â†’ Extrai texto do PDF                                  â”‚
â”‚     â†“                                                        â”‚
â”‚  3. CHUNKING (retriever.py)                                 â”‚
â”‚     â†’ Divide em pedaÃ§os consistentes (512 chars)           â”‚
â”‚     â†“                                                        â”‚
â”‚  4. EMBEDDINGS (sentence-transformers)                      â”‚
â”‚     â†’ Converte para vetores semÃ¢nticos                     â”‚
â”‚     â†“                                                        â”‚
â”‚  5. ARMAZENAMENTO (ChromaDB)                                â”‚
â”‚     â†’ Salva vetores persistentemente                        â”‚
â”‚     â†“                                                        â”‚
â”‚  6. CHAT                                                    â”‚
â”‚     â†’ Pergunta do usuÃ¡rio                                  â”‚
â”‚     â†’ Busca semÃ¢ntica por contexto relevante               â”‚
â”‚     â†’ Envia para LLM com contexto                          â”‚
â”‚     â†’ Retorna resposta contextualizada                     â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Estrutura do RepositÃ³rio

```
EixoAi/
â”œâ”€â”€ .env                      # ConfiguraÃ§Ã£o (GROQ_API_KEY)
â”œâ”€â”€ .gitignore               # Arquivos ignorados
â”œâ”€â”€ requirements.txt         # DependÃªncias Python
â”œâ”€â”€ README.md                # Este arquivo
â”‚
â”œâ”€â”€ src/                     # CÃ³digo-fonte principal
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py               # Interface Gradio (INÃCIO AQUI)
â”‚   â”œâ”€â”€ ingester.py          # ExtraÃ§Ã£o de PDFs
â”‚   â”œâ”€â”€ llm_chain.py         # IntegraÃ§Ã£o com Groq LLM
â”‚   â””â”€â”€ retriever.py         # Busca semÃ¢ntica com ChromaDB
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ uploads/             # PDFs carregados pelos usuÃ¡rios
â”‚
â””â”€â”€ vector_db/               # Banco de dados de embeddings (ChromaDB)
    â”œâ”€â”€ chroma.parquet
    â””â”€â”€ index/
```

### ğŸ“ DescriÃ§Ã£o dos MÃ³dulos

| Arquivo | FunÃ§Ã£o |
|---------|--------|
| **`app.py`** | Interface Gradio com upload de PDF e chat em tempo real |
| **`ingester.py`** | LÃª PDFs e extrai texto usando PyPDF |
| **`llm_chain.py`** | Gerencia conversa com Groq API, histÃ³rico e prompts |
| **`retriever.py`** | **Core do RAG**: chunking, embeddings, busca semÃ¢ntica |
| **`test.py`** | Menu de testes para validar cada componente |

---

## ğŸš€ Quick Start

### PrÃ©-requisitos
- Python 3.10+
- pip ou uv
- Chave Groq (gratuita em https://console.groq.com)

### 1ï¸âƒ£ InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone https://github.com/seu-usuario/EixoAi.git
cd EixoAi

# Crie ambiente virtual (opcional)
python -m venv .venv
.venv\Scripts\activate  # Windows
source .venv/bin/activate  # Linux/Mac

# Instale dependÃªncias
pip install -r requirements.txt
```

### 2ï¸âƒ£ Configure Groq API

```bash
# Edite .env e adicione sua chave:
# GROQ_API_KEY=gsk_seu_token_aqui
```

Obtenha em: https://console.groq.com

### 3ï¸âƒ£ Execute a AplicaÃ§Ã£o

**Interface Web (Gradio):**
```bash
python src/app.py
# Acesse: http://localhost:7860
```

---

## ğŸ’¡ Como Usar

### Via Interface Web

1. **FaÃ§a Upload de um PDF**
   - Clique em "Selecione um PDF"
   - O sistema extrai e processa automaticamente
   - Gera embeddings para busca semÃ¢ntica

2. **Converse com a IA**
   - Digite sua pergunta
   - O sistema busca contexto relevante automaticamente
   - A LLM responde com base no PDF

3. **Limpe e Recomece**
   - "Limpar Tudo" remove o PDF e histÃ³rico

---

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### Ajustar Tamanho de Chunks

Em `src/retriever.py`:
```python
CHUNK_SIZE = 512        # Aumentar = contexto maior
CHUNK_OVERLAP = 100     # Aumentar = melhor continuidade
```

### Mudar Modelo LLM

Em `src/llm_chain.py`:
```python
model = "llama-3.1-70b-versatile"  # Modelos disponÃ­veis
temperature = 0.7                  # 0 = determinÃ­stico, 1 = criativo
max_tokens = 1024                  # Comprimento da resposta
```

### Mudar Modelo de Embeddings

Em `src/retriever.py`:
```python
MODEL_NAME = "all-MiniLM-L6-v2"  # Leve e rÃ¡pido
# Alternativas:
# "all-mpnet-base-v2" - Mais preciso (lento)
# "multilingual-e5-small" - Para mÃºltiplos idiomas
```

---

## ğŸ“Š Exemplo de Funcionamento

```
Usuario: "Qual Ã© o objetivo principal?"

Sistema:
1. Busca semÃ¢ntica no PDF â†’ Encontra 3 chunks relevantes
2. Monta contexto com chunks + pergunta
3. Envia para LLM com instruÃ§Ã£o
4. LLM responde contextualizadamente

Resposta: "O objetivo principal Ã©..."
```

---

## ğŸ”— DependÃªncias

```
pypdf==6.6.0                    # Leitura de PDFs
gradio==6.3.0                   # Interface web
chromadb==1.4.1                 # Banco vetorial
sentence-transformers==5.2.0    # Embeddings
langchain==1.2.4                # OrquestraÃ§Ã£o LLM
langchain-groq==1.1.1           # Plugin Groq
python-dotenv==1.2.1            # VariÃ¡veis de ambiente
```

---

## ğŸš¨ Troubleshooting

### Erro: "GROQ_API_KEY nÃ£o definida"
```bash
# Verifique se .env existe
cat .env
# Deve ter: GROQ_API_KEY=gsk_...
```

### Erro: "PDF nÃ£o contÃ©m texto"
- PDFs escaneados precisam de OCR (nÃ£o suportado ainda)
- Tente com PDFs com texto selecionÃ¡vel

### Erro: "Modelo de embeddings nÃ£o encontrado"
```bash
# Baixa o modelo automaticamente na primeira execuÃ§Ã£o
# Se travar, download manual:
python -m sentence_transformers.models.download all-MiniLM-L6-v2
```

### ChromaDB com erro de permissÃ£o
```bash
# Limpe o banco:
rm -rf vector_db/
# SerÃ¡ recriado automaticamente
```

---

## ğŸ“ˆ Roadmap

- [ ] Suporte a mÃºltiplos PDFs simultÃ¢neos
- [ ] HistÃ³rico persistente de conversas
- [ ] OCR para PDFs escaneados
- [ ] Dashboard de analytics
- [ ] Exportar conversas (JSON/PDF)
- [ ] Interface mobile
- [ ] Deploy em produÃ§Ã£o (Docker)

---

## ğŸ¤ Contribuindo

Sinta-se Ã  vontade para:
- Reportar bugs
- Sugerir melhorias
- Fazer pull requests
- Melhorar documentaÃ§Ã£o

---

## ğŸ“„ LicenÃ§a

MIT License - veja LICENSE para detalhes

---

## ğŸ‘¨â€ğŸ’» Autor

**Kaio W. B.** - [GitHub](https://github.com/kaio-w-b)

---

## ğŸ“š Recursos Ãšteis

- [DocumentaÃ§Ã£o Groq](https://console.groq.com/docs)
- [Sentence Transformers](https://www.sbert.net/)
- [ChromaDB](https://www.trychroma.com/)
- [Gradio](https://gradio.app/)
- [RAG Explainer](https://docs.langchain.com/docs/modules/chains/popular/qa_with_sources)

---

**Ãšltima atualizaÃ§Ã£o:** 17 de Janeiro de 2026
**VersÃ£o:** 1.0.0